# УЧЕБНАЯ ПРАКТИКА (научно-исследовательская работа 1 сем)

## 1.1 Формирование электронной среды "Магистерская диссертация" (этапы идентификации и концептуализации)

Отчетом является факт наличия данного репозитория

## 1.2. Провести анализ состояния проблемы, исследуемой в рамках магистерской диссертации. Подготовить рабочие материалы для Параграфа 1 .1 магистерской диссертации.

Планируемая ВКР: описать и сопоставить данные 2020–2025 гг. о том, как генеративный ИИ влияет на успеваемость/учебные результаты и на практики академической честности, а также какие нормы и решения складываются у студентов и преподавателей [План ВКР](https://github.com/LyoshaGodX/mag_practice_2025_winter/blob/1e5c8caecf31ecc93ddee627a22f45aa6a460fc3/%D0%9F%D0%BB%D0%B0%D0%BD%20%D0%92%D0%9A%D0%A0.pdf).

В качестве основной теоретической рамки удобно связать принятие/использование технологии (TAM/UTAUT2/модели принятия и продолжения использования) с эффектами на обучение и оценивание и рисками/нормами академической честности и институциональными ответами.

### Аспект 1: использование и принятие GenAI

* Examining Students’ Acceptance and Use of ChatGPT in Saudi Arabian Higher Education (UTAUT2, 2024) [1](https://www.mdpi.com/2254-9625/14/3/47)
* Understanding University Students’ Acceptance of ChatGPT: Insights from the UTAUT2 Model (2024) [2](https://www.tandfonline.com/doi/pdf/10.1080/08839514.2024.2371168)
* ChatGPT in higher education: factors influencing ChatGPT user satisfaction and continued use intention (TAM/SEM, 2024) [3](https://www.frontiersin.org/articles/10.3389/feduc.2024.1354929/pdf)
* Perceptions and usage of AI chatbots among students in higher education across genders, academic levels and fields of study (2024) [4](https://linkinghub.elsevier.com/retrieve/pii/S2666920X24000626)
* Exploring Computer Science Students’ Perception of ChatGPT in Higher Education: A Descriptive and Correlation Study (2023) [5](https://www.mdpi.com/2227-7102/13/9/924/pdf)
* Exploring University Students’ Adoption of ChatGPT Using the Diffusion of Innovation Theory and Sentiment Analysis With Gender Dimension (2023) [6](https://onlinelibrary.wiley.com/doi/10.1155/2024/3085910)
* WIP: Faculty Perceptions of ChatGPT – A Survey in Engineering Education (TAM-ориентированный опрос, 2024) [7](https://ieeexplore.ieee.org/document/10893393/)
* Assessing ChatGPT’s impact on curriculum outcomes and Entrustable Professional Activities during APPEs (опрос о влиянии на outcomes, 2024) [8](https://pharmacyeducation.fip.org/pharmacyeducation/article/view/2916)
* AI-Assisted Scholarly Writing in Education: A Scoping Review (2019–2024) (обзор по AI-assisted writing в образовании, 2024) [9](https://bulletin-pedagogy.kaznpu.kz/index.php/ped/article/view/4433/1068)
* An In-Depth Review of ChatGPT’s Pros and Cons for Learning and Teaching in Education (обзор, 2024) [10](https://online-journals.org/index.php/i-jim/article/view/46509)

### Аспект 2: эффекты на обучение и успеваемость

* Impact of the Implementation of ChatGPT in Education: A Systematic Review (2023) [11](https://www.mdpi.com/2073-431X/12/8/153/pdf)
* Empowering learners with ChatGPT: insights from a systematic literature exploration (2024) [12](https://link.springer.com/10.1007/s44217-024-00120-y)
* Critical analysis of the technological affordances, challenges and future directions of Generative AI in education: a systematic review (2024) [13](https://www.tandfonline.com/doi/full/10.1080/02188791.2024.2305156)
* Generative AI and Higher Education: Trends, Challenges, and Future Directions from a Systematic Literature Review (2024) [14](https://www.mdpi.com/2078-2489/15/11/676)
* Harnessing Generative AI (GenAI) for Automated Feedback in Higher Education: A Systematic Review (2024) [15](https://olj.onlinelearningconsortium.org/index.php/olj/article/view/4593)
* The Impact of Artificial Intelligence Tools on Academic Writing Instruction in Higher Education: A Systematic Review (2024) [16](https://awej.org/the-impact-of-artificial-intelligence-tools-on-academic-writing-instruction-in-higher-education-a-systematic-review/)
* Analyzing the role of ChatGPT as a writing assistant at higher education level: A systematic review of the literature (2023) [17](https://www.cedtech.net/article/analyzing-the-role-of-chatgpt-as-a-writing-assistant-at-higher-education-level-a-systematic-review-13605)
* Testing the Ability of Teachers and Students to Differentiate between Essays Generated by ChatGPT and High School Students (2023) [18](https://downloads.hindawi.com/journals/hbet/2023/1923981.pdf)
* Artificial intelligence in academic literacy (2025) [19](https://www.frontiersin.org/articles/10.3389/feduc.2025.1701238/full)
* Examining the use of ChatGPT in public universities in Hong Kong (2024) [20](https://link.springer.com/10.1007/s44217-023-00081-8)

### Аспект 3: академическая честность, оценивание, политика

* Generative AI and higher education (2024) [21](https://link.springer.com/10.1007/s10734-024-01265-3)
* Generative AI chatbots in higher education (2024) [22](https://link.springer.com/10.1007/s10734-024-01288-w)
* Academic integrity violations in higher education (2024) [23](https://www.emerald.com/jarhe/article/17/5/1454/1258398)
* An integrative decision-making framework (2024) [24](https://peerj.com/articles/cs-1845)
* Academic integrity and contract cheating policy analysis (2019) [25](https://edintegrity.biomedcentral.com/articles/10.1007/s40979-019-0042-4)
* Staff views on commercial contract cheating (2019) [26](http://link.springer.com/10.1007/s10734-019-00360-0)
* The Perceptions of Higher Education Students on Contract Cheating (2019) [27](https://journalhosting.ucalgary.ca/index.php/jet/article/view/69722)
* Why Students Do Not Engage in Contract Cheating (2019) [28](https://www.frontiersin.org/articles/10.3389/fpsyg.2019.02229/pdf)
* Detection of Online Contract Cheating Through Stylometry (2020) [29](https://olj.onlinelearningconsortium.org/index.php/olj/article/download/2096/938)
* Fear of failure: motivations for contract cheating (2024) [30](https://www.tandfonline.com/doi/full/10.1080/2331186X.2024.2413211)

### Российские источники и источники о российском контексте

* Политика российских вузов в отношении академического мошенничества студентов: наказание или воспитание? (2020) [31](https://elar.urfu.ru/bitstream/10995/98033/1/UM_2020_4_30-45.pdf)
* Влияние дистанционного обучения на плагиат и списывание (2021) [32](https://s.top-technologies.ru/pdf/2021/3/38548.pdf)
* Методика и технология объективной оценки заимствований в академических текстах (2020) [33](https://openedu.rea.ru/jour/article/download/770/506)
* Институциональные ловушки в научно-образовательной сфере: природа и механизм устранения (2020) [34](https://www.edscience.ru/jour/article/download/1853/952)
* Нарративный анализ институциональных ловушек образования и науки в России (2023) [35](http://hjournal.ru/files/JIS_11_1/JIS_11.1_11.pdf)
* Дистанционное обучение в образовательной системе высшей школы: опыт осмысления и приоритетные направления совершенствования (2023) [36](https://jpl-journal.ru/index.php/journal/article/download/231/232)
* Концепция цифровой трансформации классического университета в «цифровой университет» (2020) [37](https://e-management.guu.ru/jour/article/download/99/75)
* Анализ тенденций развития высшего образования в условиях цифровой трансформации общества (2024) [38](https://s.science-education.ru/pdf/2023/4/32858.pdf)
* Электронная обучающая платформа и педагогический мониторинг в условиях цифровой трансформации (2021) [39](https://vovr.elpub.ru/jour/article/download/2748/1656)
* Адаптивное персонализированное обучение: внедрение современных технологий в высшем образовании (2023) [40](https://info.infojournal.ru/jour/article/download/974/660)
* Подготовка специалистов в высших учебных заведениях в реалиях цифровой трансформации (2024) [41](https://s.science-education.ru/pdf/2023/6/33052.pdf)
* Вопросы проектирования эффективных образовательных программ по направлению «Прикладная информатика» в условиях инновационного развития (2020) [42](https://openedu.rea.ru/jour/article/download/752/488)
* Трансформация модели дополнительного образования в условиях цифровой экономики (2019) [43](https://openedu.rea.ru/jour/article/download/603/425)
* Роль искусственного интеллекта в цифровой трансформации современной россии (2023) [44](https://s.science-engineering.ru/pdf/2023/2/1432.pdf)
* Чат-боты как компонент содержания обучения основам искусственного интеллекта в школе (2022) [45](https://school.infojournal.ru/jour/article/download/624/620)

## 1.3. Провести сопоставительный анализ изученных источников.

### Генеративный ИИ в образовании: влияние на успеваемость и академическую честность (сопоставительный анализ 2020–2025)

#### Введение

С появлением мощных генеративных моделей ИИ (в первую очередь ChatGPT с конца 2022 года) мировое академическое сообщество активно обсуждает, как эти технологии влияют на обучение и успеваемость студентов, а также на практики академической честности. Исследования последних лет показывают, что интерес студентов к использованию ChatGPT высок во многих странах, поскольку он может помогать в обучении, однако вызывает и серьезные опасения по поводу возможного мошенничества. Встает вопрос: действительно ли способы реагирования системы образования на GenAI универсальны во всем мире, отличаясь лишь деталями регулирования и решениями проблемы, или же существуют принципиальные различия между странами? В данном анализе, опираясь на источники 2020–2025 гг., сопоставляются данные о принятии и использовании генеративного ИИ в высшем образовании, его влиянии на результаты обучения, а также о возникающих рисках для академической честности и мерах, предпринимаемых образовательными институтами. Особое внимание уделено российскому опыту на фоне международных тенденций.

#### Принятие и использование GenAI студентами и преподавателями

Исследования показывают, что студенты по всему миру в целом проявляют интерес и готовность использовать ChatGPT и схожие инструменты ИИ в учебных целях. Ключевыми факторами, влияющими на принятие технологии, являются воспринимаемая полезность и удобство использования. Так, структурированное опросное исследование в Саудовской Аравии выявило, что намерение студентов пользоваться ChatGPT напрямую зависит от ожидаемой эффективности технологии в учебе, ее простой и понятного интерфейса, а также социального влияния (например, мнения сверстников) [1](https://www.mdpi.com/2254-9625/14/3/47). Эти же факторы (соответствующие компонентам модели UTAUT2) во многом обусловливают и сам факт использования: если студент считает, что ChatGPT поможет ему достигать академических целей, и видит, что окружающие положительно относятся к этому, он с высокой вероятностью начнет регулярно применять ИИ-инструмент [1](https://www.mdpi.com/2254-9625/14/3/47). Схожие выводы получены и на других выборках. Например, исследование, проведенное в Норвегии, также подтвердило, что наибольшее влияние на намерение студентов использовать ChatGPT оказывает ожидаемая полезность, а среди уже начавших пользоваться заметную роль играет фактор привычки [2](https://www.tandfonline.com/doi/pdf/10.1080/08839514.2024.2371168). Иными словами, в разных странах студенты сходятся во мнении, что если технология очевидно улучшает их учебный процесс, они готовы ее принять, и по мере накопления опыта ИИ прочно входит в их учебные практики.

Помимо полезности и простоты, на удовлетворенность студентов и длительное использование ChatGPT влияют и дополнительные нюансы. Например, исследование в южнокорейском вузе с позиций модели TAM показало, что совместимость ChatGPT с учебными задачами положительно сказывается на ощущении легкости работы с ним, а эффективность (то есть быстрота и результативность получения ответа) усиливает воспринимаемую полезность [3](https://www.frontiersin.org/articles/10.3389/feduc.2024.1354929/pdf). В свою очередь, и легкость, и полезность значимо повышают удовлетворенность пользователей, что ведет к их намерению продолжать пользоваться ИИ-чатботом в дальнейшем [3](https://www.frontiersin.org/articles/10.3389/feduc.2024.1354929/pdf). Таким образом, в целом результаты разных исследований гармонично дополняют друг друга: студенты хотят, чтобы инструмент ИИ был не только полезным в учебе, но и простым и эффективным, тогда он становится для них привычным помощником.

При этом степень принятия ChatGPT может различаться в отдельных демографических группах и контекстах обучения. Большое опросное исследование в Швеции (почти 6000 студентов из разных университетов) выявило широкую осведомленность о ChatGPT: более половины студентов уже имеют положительное отношение к использованию чатботов в образовании, однако примерно столько же выражают и обеспокоенность по поводу их дальнейшего влияния [4](https://linkinghub.elsevier.com/retrieve/pii/S2666920X24000626). Интересно, что женщины и учащиеся гуманитарных и медицинских направлений оказались настроены заметно более скептически: они чаще выражали опасения относительно роли ИИ в обучении и оценивании, тогда как мужчины, а также студенты инженерно-технических специальностей демонстрируют более активное использование и больший оптимизм в отношении GenAI [4](https://linkinghub.elsevier.com/retrieve/pii/S2666920X24000626). Эти различия подчёркивают, что восприятие технологии частично зависит от бэкграунда: например, представители технических дисциплин могут лучше понимать принцип работы ИИ и видеть в нём инструмент, тогда как гуманитарии и медики больше обеспокоены этическими и практическими рисками. Тем не менее, во всех группах присутствует значительный интерес к ChatGPT – даже среди более осторожных студентов немало тех, кто уже пробует его применять в учёбе.

Кроме студентов, важную роль играет и отношение преподавателей к новым технологиях. Предварительные исследования показывают, что и среди профессорско-преподавательского состава отношение неоднозначное, но эволюционирующее. Например, опрос инженерно-педагогических работников (WIP-исследование) указывает, что многие преподаватели признают потенциальную полезность ChatGPT для повышения эффективности подготовки материалов и обратной связи студентам, хотя параллельно испытывают беспокойство насчет нечестного использования студентами [7](https://ieeexplore.ieee.org/document/10893393/). В первые месяцы после появления ChatGPT ряд университетов и отдельных педагогов реагировали настороженно, некоторые запрещали использование ИИ на экзаменах и заданиях. Однако по мере понимания возможностей инструмента всё больше преподавателей проявляют интерес к интеграции чатбота в учебный процесс для рутинных задач или как ассистента, при условии разработки ясных правил его применения. В целом, можно сказать, что и студенты, и преподаватели во многих странах проходят схожие стадии принятия GenAI: от любопытства и экспериментов – к осознанию пользы – и далее к попыткам встроить технологию в образовательную практику, параллельно обсуждая сопутствующие риски.

#### Эффекты генеративного ИИ на обучение и успеваемость

Массовое распространение ChatGPT поставило вопрос: действительно ли использование таких инструментов улучшает академические результаты и качество обучения, либо же студенты учатся хуже, полагаясь на машину? Ещё в 2023 году начали выходить систематические обзоры, пытающиеся обобщить первые эффекты. В одном из первых обзоров отмечалось, что применение ChatGPT в образовании может повышать эффективность обучения, ускоряя поиск информации и получение обратной связи студентами, однако одновременно авторы подчеркивали возникшие опасения – от поверхностного усвоения знаний до злоупотреблений для списывания [11](https://www.mdpi.com/2073-431X/12/8/153/pdf). В целом литература рисует сбалансированную картину: генеративный ИИ обладает значительными образовательными преимуществами, но максимизировать их можно только при правильной педагогической интеграции, иначе есть риск негативных последствий.

Положительные эффекты. Многие работы отмечают, что ChatGPT и аналогичные модели могут служить своего рода персонализированными помощниками для студентов. Например, они способны быстро объяснить сложные концепции простым языком, ответить на уточняющие вопросы, предоставить дополнительные примеры. Это особенно ценно в условиях больших потоков, где у преподавателя ограничено время на индивидуальную работу с каждым. Согласно обзору [12](https://link.springer.com/10.1007/s44217-024-00120-y), появилась серия кейсов, где ChatGPT применялся как тьютор: студенты задавали ему вопросы по учебному материалу и получали мгновенные разъяснения. Отмечается, что такой подход может расширять возможности обучающихся, делая обучение более самостоятельным – при условии, что ответы ИИ правильны. Еще одна сфера – развитие навыков письма: несколько исследований проверяли ChatGPT как ассистент для написания сочинений и отчетов. Систематический обзор [17](https://www.cedtech.net/article/analyzing-the-role-of-chatgpt-as-a-writing-assistant-at-higher-education-level-a-systematic-review-13605) показал, что ИИ-ассистент помогает генерировать идеи, создавать черновики текстов и исправлять грамматические ошибки, благодаря чему студенты могут быстрее проходить стадию первого наброска и фокусироваться на содержательном улучшении работы. В ряде случаев качество письменных работ студентов действительно повышалось при разумном использовании таких инструментов. Кроме того, генеративный ИИ начал применяться для автоматизированной обратной связи: например, в обзоре [15](https://olj.onlinelearningconsortium.org/index.php/olj/article/view/4593) приведены результаты экспериментов, где ChatGPT генерировал комментарии и советы по улучшению черновиков студенческих работ. Выяснилось, что своевременная подсказка ИИ может помочь ученику увидеть свои ошибки раньше, не дожидаясь проверки преподавателя, что потенциально ведет к лучшему усвоению материала. Таким образом, при правильной настройке и контроле качество обучения может выигрывать – ИИ берёт на себя часть рутинных функций наставника, ускоряет получение знаний и дает новые инструменты для самосовершенствования.

Отрицательные и спорные эффекты. Наряду с плюсами, литература констатирует и ряд проблем и рисков, способных нивелировать пользу от ИИ. Одна из главных проблем – поверхностность обучения. Если студент получает готовый ответ от ChatGPT, минуя процесс самостоятельного поиска и размышления, страдает глубина понимания. В критическом обзоре [13](https://www.tandfonline.com/doi/full/10.1080/02188791.2024.2305156) отмечается, что студенты могут привыкнуть полагаться на готовые решения, что снизит развитие их критического мышления и навыков решения проблем. Более того, ChatGPT иногда дает неточные или упрощенные ответы, а неопытный учащийся может этого не заметить. В работах подчёркивается, что без навыка проверки фактов и должного скептицизма использование ИИ может привести к закреплению заблуждений у студентов. Второй крупный риск – снижение практических навыков. Например, если ИИ исправляет все грамматические ошибки, то студент меньше учится грамотно писать сам; если генерирует код, программист-новичок может не освоить базовые алгоритмические умения. Обзор по влиянию ИИ на академическую грамотность [19](https://www.frontiersin.org/articles/10.3389/feduc.2025.1701238/full) акцентирует, что интеграция ИИ в академическое письмо должна происходить под педагогическим руководством: важно, чтобы студенты продолжали осваивать навыки анализа, аргументации, стиля, а ИИ-инструмент использовали для вспомогательных задач. Иначе есть риск, что новое поколение студентов будет хуже сформировано в плане традиционной грамотности, компенсируя пробелы через ИИ – но это сделает их уязвимыми, если инструмент недоступен или ошибается.

Отдельно следует упомянуть эффект на оценивание успеваемости. Если студенты начинают активно пользоваться ChatGPT при выполнении заданий, то традиционные оценочные работы перестают надежно отражать их собственные знания. Учителя сталкиваются с вызовом: как отличить, где студент продемонстрировал свой навык, а где ответ сгенерирован моделью. Экспериментальное исследование, проведенное в 2023 году, наглядно показало сложность этой задачи: преподаватели школ смогли правильно отличить ученическое эссе от сгенерированного ChatGPT только в ~70% случаев, а сами старшеклассники – лишь в ~62% случаев [18](https://downloads.hindawi.com/journals/hbet/2023/1923981.pdf). Причем нередко учителя ошибочно полагали лучшую, более грамотно написанную работу – продуктом ИИ, а не учеником [18](https://downloads.hindawi.com/journals/hbet/2023/1923981.pdf). Это означает, что привычные критерии оценивания «по тексту» начинают давать сбой, что чревато как пропуском случаев списывания с помощью ИИ, так и несправедливыми подозрениями в адрес добросовестных, но сильных учеников. Таким образом, влияние GenAI на успеваемость нельзя оценить однозначно без переосмысления системы оценивания: в одних случаях он повышает результативность обучения, в других – искажает сам процесс контроля знаний.

Современные обзоры сходятся во мнении, что будущее образование должно адаптироваться под новые реалии. Генеративный ИИ воспринимается не только как нарушитель спокойствия, но и как катализатор полезных изменений [21](https://link.springer.com/10.1007/s10734-024-01265-3). В частности, обсуждается необходимость реформировать систему заданий и экзаменов так, чтобы они оценивали не механическое воспроизведение информации (которое легко поручить ИИ), а подлинное понимание и навыки, например больше устных экзаменов, практических проектов, коллаборативной работы. Многие эксперты призывают включать навыки работы с ИИ в учебные программы и преподавать их открыто, а не пытаться игнорировать существование ChatGPT [22](https://link.springer.com/10.1007/s10734-024-01288-w). Такая интеграция, по задумке, позволит студентам извлекать пользу из новых технологий (например, для творческих проектов, исследований, самообучения), одновременно развивая у них этическую ответственность и умение учиться автономно. В итоге влияние GenAI на обучение может стать преимущественно положительным, если система образования эволюционирует: фокус сместится с запоминания фактов на развитие компетенций, а генеративный ИИ станет обычным инструментом, как калькулятор или текстовый редактор, использование которого оговаривается правилами и дополняет, а не заменяет мыслительную работу студентов.

#### Академическая честность: вызовы и ответная реакция

Практически сразу после появления ChatGPT на широком горизонте встал вопрос академической честности. Возможность генерировать уникальные тексты по заданной теме мгновенно породила опасения: не хлынет ли новая волна плагиата и контрактного списывания, когда студенты будут выдавать ответы ИИ за свои собственные? Исследования последних лет, обобщенные в ряде обзоров, показывают, что проблема академического мошенничества в высшей школе не нова – задолго до эры ИИ студенты прибегали к списыванию, скачиванию готовых работ из интернета и заказу эссе на стороне [25](https://edintegrity.biomedcentral.com/articles/10.1007/s40979-019-0042-4) [27](https://journalhosting.ucalgary.ca/index.php/jet/article/view/69722). Мотивы этого тоже хорошо изучены: страх провала и чрезмерное давление ради оценок – одни из главных причин, заставляющих учащихся решиться на нечестный шаг [30](https://www.tandfonline.com/doi/full/10.1080/2331186X.2024.2413211). В то же время многие студенты не вовлекаются в мошенничество именно по этическим убеждениям или из понимания ценности собственных знаний [28](https://www.frontiersin.org/articles/10.3389/fpsyg.2019.02229/pdf). Появление генеративного ИИ изменило инструмент, но не базовую дилемму: те, кто прежде мог списать, получили новый удобный способ, а те, кто принципиально учится честно, скорее всего, продолжат придерживаться принципов. Однако легкость, с которой ChatGPT может генерировать ответы, резко снижает порог входа в мошенничество – даже добросовестного студента может соблазнить идея слегка «подправить» свой текст через ИИ или проверить решение задачи. Это ставит перед университетами всего мира задачу выработать адекватную политику и меры в отношении GenAI, чтобы сохранить академическую этику без торможения прогресса.

Международные дискуссии 2023–2024 гг. демонстрируют удивительно похожие подходы в разных странах. Первоначальная реакция многих вузов заключалась в разработке временных запретительных мер или предупреждений. Но постепенно становится ясно, что полный запрет неэффективен (студенты могут работать с ИИ вне аудитории, а распознать это сложно) и, более того, лишает их важных навыков работы с современной технологией. Поэтому тренд смещается к формулированию чётких границ дозволенного использования и обучению студентов этичному обращению с ИИ. Например, в Гонконге изначально возникла уникальная ситуация: OpenAI сама ограничила доступ ChatGPT для региона, и университеты вынужденно столкнулись с его отсутствием на кампусах [20](https://link.springer.com/10.1007/s44217-023-00081-8). Это подтолкнуло их к разработке специальных политик: сначала официальные лица проявляли осторожность, но со временем перешли к проактивной стратегии интеграции – были изданы временные рекомендации по допустимому применению ИИ в курсах, подчеркнуты требования ссылаться на использование ChatGPT при подготовке заданий, а также начата работа над обучающими мероприятиями для преподавателей и студентов [20](https://link.springer.com/10.1007/s44217-023-00081-8). Пример Гонконга иллюстрирует общую тенденцию: сначала шок и ограничения, затем осознание неизбежности технологии и попытка встроить ее в образовательную среду на ясных условиях.

Ключевой упор делается на обновление норм академической честности. Университеты в разных странах выпускают рекомендации, где оговаривают, при каких обстоятельствах студент может воспользоваться ИИ. Часто разрешается использовать ChatGPT для получения объяснений, идей или проверки кода, но запрещается выдавать его сгенерированный текст за свою оригинальную работу без проверки и доработки. Требование указывать факт применения ИИ (например, в примечании к работе) становится все более распространенным. Параллельно, для сдерживания недобросовестного поведения, разрабатываются и технические решения – от использования детекторов AI-текста до метода сравнения стиля (стилометрия). Интересно, что методы, изначально применявшиеся для выявления контрактного cheating (например, анализ стиля письменных работ студента на предмет несоответствия его обычному уровню [29](https://olj.onlinelearningconsortium.org/index.php/olj/article/download/2096/938)), сейчас адаптируются и под ловлю «следов ИИ». Однако точность таких методов пока оставляет желать лучшего, особенно учитывая способность моделей перефразировать текст и разнообразить стиль. Результаты того же эксперимента [18](https://downloads.hindawi.com/journals/hbet/2023/1923981.pdf) показывают, что даже люди-эксперты затрудняются определить авторство текста. Это служит аргументом в пользу того, что бороться нужно не только «вилкой над тарелкой», пытаясь вычислить обманщиков, но и превентивно – меняя саму культуру и дизайн обучения.

В исследованиях подчёркивается необходимость баланса между инновациями и целостностью образования. Один из подходов – это принятие институциональных решений, основанных на четких принципах. Так, в работе [24](https://peerj.com/articles/cs-1845) предложена интегративная модель принятия решений для выработки политики использования ChatGPT: университетам рекомендуется учитывать педагогические выгоды, этические соображения и мнение всех стейкхолдеров (студентов, преподавателей, администраций) при формировании регламента. Такой взвешенный, коллективный подход позволяет избежать как излишней либеральности (которая может подорвать доверие к оценкам), так и излишней репрессивности (которая препятствует развитию новых форм обучения).

Интересно отметить, что обзор ранних публикаций о ChatGPT в образовании выявил определённое смещение нарративов: в материалах первых месяцев 2023 г. студенты зачастую рисовались либо как нарушители (плагиаторы), либо как жертвы устаревшей системы оценки, вынужденные обращаться к ИИ [21](https://link.springer.com/10.1007/s10734-024-01265-3). Однако уже тогда прослеживался в целом позитивный тон: большинство авторов воспринимали появление GenAI не как конец академической честности, а как толчок переосмыслить существующие проблемы (например, перегруженность студентов, шаблонность заданий) и сделать образование более честным и увлекательным [21](https://link.springer.com/10.1007/s10734-024-01265-3). Сходным образом, другой обзор [22](https://link.springer.com/10.1007/s10734-024-01288-w) подчеркнул, что академическое сообщество видит смысл не в попытке вернуть «старые добрые времена» до ChatGPT, а в том, чтобы адаптировать нормы: например, обучать студентов, как правильно включать ИИ-генерированный контент в свои работы (через цитирование, критическую оценку), и одновременно совершенствовать систему оценивания, вводя более аутентичные задания, требующие личного опыта или творческого подхода, что затрудняет бессмысленное использование ИИ.

Конечно, задача эта непростая и требует времени. И хотя единых универсальных стандартов пока нет, уже можно утверждать, что мировое академическое сообщество движется в одном направлении: признание генеративного ИИ как новой реальности и поиск путей превратить его из угрозы в союзника обучения, сохранив при этом фундаментальные ценности честности. В разных странах различаются конкретные меры (где-то строже дисциплинарные наказания, где-то упор на просвещение и профилактику), но суть проблем и решений очень схожа, потому что природа технологии и человеческих реакций на нее интернациональна.

#### Российский опыт и контекст

Российская система высшего образования столкнулась с вызовами цифровой эпохи параллельно с мировой, хотя распространение инструментов вроде ChatGPT здесь имеет свои нюансы. Стоит отметить, что официально сервис ChatGPT от OpenAI не был доступен пользователям из России (OpenAI заблокировала доступ по ряду юрисдикций), однако продвинутые пользователи могли обходить ограничения через VPN или применять альтернативные русскоязычные модели ИИ. Тем не менее, вопросы академической честности и цифровой трансформации образования в России обсуждались еще до появления современных генерирующих моделей. В исследованиях отмечается, что проблема студенческого мошенничества – списывания, плагиата, обращения к чужой помощи при выполнении работ – весьма распространена и в российских вузах [31](https://elar.urfu.ru/bitstream/10995/98033/1/UM_2020_4_30-45.pdf). Более того, она носит системный характер и, по мнению ряда экспертов, стала своего рода «институциональной ловушкой» образования [34](https://www.edscience.ru/jour/article/download/1853/952). Иными словами, культурные и организационные особенности (например, ориентация на формальные показатели успеваемости, недостаточное внимание к привитию ценностей академической этики) поддерживают высокий уровень терпимости к нечестным практикам. Это подтверждается и исследованиями дискурса: анализ этических документов российских вузов показал, что хотя руководители декларируют неприятие мошенничества, в риторике часто превалирует карательный подход (наказание нарушителей), тогда как ценностное воспитание честности развито слабо [31](https://elar.urfu.ru/bitstream/10995/98033/1/UM_2020_4_30-45.pdf). Для сравнения, за рубежом в последние годы набирает силу тенденция смещать фокус с наказания на профилактику и формирование у студентов внутренней приверженности академической этике [31](https://elar.urfu.ru/bitstream/10995/98033/1/UM_2020_4_30-45.pdf).

Пандемия COVID-19 и вынужденный переход на дистанционное обучение в 2020–2021 гг. обнажили и усугубили проблему нечестного выполнения заданий. Согласно одному из российских исследований, в удаленном формате резко возросла частота списывания и плагиата – возможность работать вне непосредственного контроля преподавателя спровоцировала некоторых студентов чаще прибегать к недобросовестным стратегиям [32](https://s.top-technologies.ru/pdf/2021/3/38548.pdf). В ответ многие вузы усилили использование систем антиплагиата и прокторинга. Российские разработчики и университеты еще до ChatGPT активно внедряли программные средства для обнаружения заимствований в текстах студенческих работ [33](https://openedu.rea.ru/jour/article/download/770/506). Такие системы, хотя и помогают выявлять классический копипаст, перед лицом генеративного ИИ теряют эффективность, ведь ChatGPT создает оригинальный текст, не обнаруживаемый в базе источников. Этот вызов пока окончательно не решен нигде, включая Россию. Вероятно, по мере распространения GenAI, российским вузам также придется переходить от простой проверки "уникальности текста" к более сложным подходам обеспечения честности – например, к собеседованиям по сданной работе, к анализу стиля студента или требованию поэтапной сдачи работы (черновики, наброски от руки и т.д.).

Стоит отметить, что в России на высшем уровне признается важность цифровой трансформации образования и внедрения элементов искусственного интеллекта. Существует концепция «Цифрового университета», предусматривающая активное использование ИТ-технологий в учебном процессе, от электронных платформ до аналитических систем обучения [37](https://e-management.guu.ru/jour/article/download/99/75). Искусственный интеллект прямо упоминается как один из драйверов таких преобразований [44](https://s.science-engineering.ru/pdf/2023/2/1432.pdf). Однако следует различать две линии: применение ИИ для улучшения организации обучения (например, интеллектуальные системы адаптивного обучения, чат-боты для помощи студентам в навигации по курсу и пр.) и использование ИИ студентами в учебной деятельности. По первой линии в России уже есть разработки и пилотные проекты – например, чат-боты-консультанты в вузах, персонализированные траектории на основе алгоритмов и т.п. [40](https://info.infojournal.ru/jour/article/download/974/660). По второй линии (генеративный ИИ как учебный инструмент) пока нет широкого освещения. Тем не менее, отдельные шаги предпринимаются: так, в сфере школьного образования обсуждается включение темы ИИ в содержание обучения. В частности, предлагалось использовать чат-боты как элемент обучения основам ИИ в школе – ученики могут посредством диалога с ботом изучать, как работают алгоритмы, или тренироваться решать задачи [45](https://school.infojournal.ru/jour/article/download/624/620). Это показывает, что в российском педагогическом сообществе есть понимание: грамотное использование ИИ – это навык, которому нужно учить с ранних этапов. Вероятно, аналогичным образом и в вузах со временем появятся курсы или модули, посвященные работе с генеративными моделями, их возможностям и ограничениям, а также вопросам этики ИИ.

Что касается официальной позиции российских вузов по отношению к студенческому использованию ChatGPT для выполнения работ, то к настоящему моменту (2025 г.) она еще формируется. Пока нет общегосударственных рекомендаций, и каждый университет, скорее всего, действует по ситуации. Можно предположить, что большинство будут опираться на уже существующие положения об академической честности и плагиате, расширяя их трактовку на генеративный контент. То есть, использование стороннего источника (в данном случае ИИ) без указания будет рассматриваться как нарушение. Однако, учитывая общемировую динамику, можно ожидать, что и в России постепенно придут к более тонкой политике: разрешать ИИ как помощник (например, для черновиков, исследования), но требовать от студента активной роли в проверке и доработке результата, а главное – его осмысления. Российские эксперты по академической этике уже подчеркивали, что воспитание ценностей у студентов эффективнее тотального контроля [31](https://elar.urfu.ru/bitstream/10995/98033/1/UM_2020_4_30-45.pdf). Возможно, появление ChatGPT станет стимулом и в наших вузах сместить акцент с карающего надзора (который стал еще сложнее) на превентивную работу: откровенный разговор со студентами о рисках бессмысленного обучения через ИИ, демонстрация последствий незнания материала, создание атмосферы доверия, в которой ценятся честные усилия.

Подводя итог российскому опыту: проблемы, поставленные генеративным ИИ, не стали уникальными – они во многом наложились на уже имевшиеся вызовы (массовое списывание, падение мотивации, необходимость цифровизации). В каких-то аспектах российские вузы оказались даже более готовыми технически (системы проверки текстов давно используются), а в каких-то – сложнее, учитывая сложившиеся практики поведения. Но в целом, российская повестка по GenAI движется в русле мировой, хотя, возможно, чуть медленнее из-за языкового барьера и геополитических особенностей доступа к технологиям. В ближайшие годы можно ожидать, что и у нас появятся более конкретные рекомендации на уровне Минобрнауки или ассоциаций университетов о том, как интегрировать ИИ в обучение без ущерба для академической честности.

#### Заключение

Анализ источников 2020–2025 годов показывает, что феномен генеративного ИИ в образовании по своей сути носит интернациональный характер. Студенты в Саудовской Аравии, Европе, Азии и других регионах демонстрируют сходное любопытство и желание использовать новые инструменты для улучшения своего обучения, а преподаватели во всем мире задаются одними и теми же вопросами о переосмыслении своих методов оценки. Выявляются общие закономерности: принятие технологии идет через призму ее полезности и удобства [12](https://link.springer.com/10.1007/s44217-024-00120-y), влияние на обучение оказывается двояким – ускоряя доступ к знаниям, ИИ одновременно бросает вызов традиционным навыкам [11](https://www.mdpi.com/2073-431X/12/8/153/pdf) [19](https://www.frontiersin.org/articles/10.3389/feduc.2025.1701238/full), а академическая честность требует новых подходов вместо старых правил [21](https://link.springer.com/10.1007/s10734-024-01265-3) [24](https://peerj.com/articles/cs-1845). Несмотря на различные национальные контексты, к настоящему моменту прослеживается удивительная конвергенция стратегий: вместо паники – стремление к адаптации, вместо запретов – разумное регулирование и обучение. Отличия между странами проявляются главным образом в скоростях и формах этой реакции. Где-то (например, англоязычные университеты) уже разработали подробные гайдлайны по использованию ChatGPT в курсовых работах, а где-то (например, многие постсоветские вузы) еще только начинают обсуждать проблему в публичном поле. Но направление движения одно: включить GenAI в образовательную экосистему на правах инструмента, чья грамотная эксплуатация должна стать частью современных компетенций. При этом везде подчеркивается, что фундаментальные академические ценности – честность, самостоятельность, критическое мышление – остаются неизменными и должны быть сохранены, даже если методы их обеспечения меняются.

Российский опыт, рассмотренный отдельно, не противоречит общемировому, а дополняет его специфическими деталями. В России, как и всюду, выявлены вызовы снижения качества обучения при злоупотреблении ИИ и риски всплеска нечестности [32](https://s.top-technologies.ru/pdf/2021/3/38548.pdf). Одновременно предпринимаются усилия встроить ИИ в цифровую трансформацию вузов [37](https://e-management.guu.ru/jour/article/download/99/75) [44](https://s.science-engineering.ru/pdf/2023/2/1432.pdf). Исторически жесткий подход к наказанию за списывание [31](https://elar.urfu.ru/bitstream/10995/98033/1/UM_2020_4_30-45.pdf) теперь сталкивается с необходимостью более гибких решений, и есть надежда, что именно интернациональная повестка GenAI подтолкнет российские вузы к более прогрессивным стратегиям: воспитанию академической культуры, обновлению программ с учетом ИИ, и одновременному развитию у студентов этики ответственности за результаты своего обучения. Общий вывод таков: взаимодействие системы образования с генеративным ИИ в разных странах отличается в деталях регулирования и темпах внедрения решений, но по сути своей универсально. Везде образовательное сообщество стремится понять новую технологию и найти лучший способ ее использования на благо обучения, минимизируя риски для честности. Такой обмен опытом – от обзоров и исследований [21](https://link.springer.com/10.1007/s10734-024-01265-3) [23](https://www.emerald.com/jarhe/article/17/5/1454/1258398) до практических кейсов – позволяет говорить о формировании глобальных норм академической работы в эпоху ИИ, где студенты и преподаватели всего мира учатся вместе преодолевать новые вызовы и использовать новые возможности.

## 1.4. Рецензирование научной статьи (по проблеме, исследуемой в магистерской диссертации). Написать рецензию на статью

### Рецензия на статью Baldrich K, Perez-García C and Santamarina-Sancho M (2025) Artificial intelligence in academic literacy: empirical evidence on reading and writing practices in higher education. Front. Educ. 10:1701238. doi: 10.3389/feduc.2025.1701238 [19](https://www.frontiersin.org/articles/10.3389/feduc.2025.1701238/full)

Представленная систематическая монография, опубликованная недавно в журнале Frontiers in Education, предлагает комплексный анализ эмпирических исследований о применении инструментов искусственного интеллекта в практиках академического чтения и письма студентов. Работа методологически строга и содержит ценные выводы, релевантные для понимания того, как генеративный ИИ трансформирует высшее образование, особенно в контексте учебных компетенций, этики и оценивания.

Авторы проводят систематический обзор согласно руководству PRISMA 2020, охватывающий период с января 2023 по апрель 2025 года. Первоначальный поиск в базах Scopus и Web of Science дал 4248 результатов, из которых после тщательной фильтрации отобрано 55 исследований, отвечающих критериям включения: наличие эмпирического содержания, использование валидированных инструментов и достаточный размер выборки (с. 3). Стоит отметить, что авторы допускают лингвистическое смещение в выборке, поскольку большинство доступных работ написано на английском языке, что может снижать ценность обхора для исследований, специфичных для неанглоязычного контекста.

Ключевое достоинство статьи заключается в её фокусе на валидированные инструменты измерения. Авторы выделяют несколько важных шкал: ChatGPT Usage Scale для классификации функционального использования инструмента, AILS-CCS scale, которая измеряет четыре измерения AI-грамотности (осведомленность, использование, оценка и этика), и SIUAIT индекс для оценки уровня институциональной интеграции ИИ-инструментов (с. 4). Статья подробно анализирует адаптации классических моделей принятия технологии, таких как TAM, TPB и UTAUT, что напрямую связано с теоретической рамкой, предложенной в плане моей ВКР.

Одной из центральных находок является то, что студенты используют ИИ прежде всего для генерации идей, структурирования текста и редактирования, движимые воспринимаемой полезностью, внутренней мотивацией и благоприятными условиями (с. 2). Эти данные созвучны первой гипотезе моего исследования (H2), согласно которой польза ИИ выше для пересказа и переработки текста, написания отчетов и рефератов, и ниже для нестандартных, творческих заданий. Baldrich и соавторы приводят свидетельства того, что, хотя студенты сообщают об улучшении качества письма, ясности и связности (с. 5), одновременно растут опасения относительно развития фундаментальных компетенций, таких как критическое мышление, оригинальность и самостоятельное обучение. Авторы отмечают, что студенты с более высокой уверенностью в академическом письме с меньшей вероятностью обращаются к ИИ (с. 6).

Раздел, посвященный этике и академической честности, заслуживает особого внимания. Исследование Johnston и соавторов, включенное в обзор, показало, что хотя большинство респондентов слышали о генеративном ИИ и более половины (2555 человек) либо использовали его, либо рассматривали такую возможность, 70,4% считали, что использование ChatGPT для написания целых эссе неприемлемо (с. 6). Одновременно обнаруживается парадокс: значительная часть студентов готова использовать ИИ неэтично, особенно если не применять наказания или санкции (Hellmich et al., 2024, цит. в обзоре, с. 6). Исследование Chan's (2025, с. 6) показывает, что студенты понимают явно неэтичное использование ИИ, но их восприятие более нюансированных случаев остается сложным, и они испытывают затруднения с концепциями цитирования и самоплагиата. Это напрямую соответствует третьему вопросу моего исследования о практиках и нормах честности, а также гипотезе H3 о том, что неясные правила курса ведут к валидации проблем и конфликтам.

Авторы выделяют пять критических тем, которые пронизывают анализируемые исследования: влияние ИИ на развитие академических навыков, этические опасения относительно целостности и авторства, необходимость развития критической цифровой грамотности, расхождения между восприятием и готовностью, а также необходимость переопределения методов оценивания (с. 1). Каждая из этих тем имеет прямое отношение к моей магистерской диссертации. Особенно значимо то, что авторы подчеркивают: интеграция ИИ в академическую грамотность должна руководствоваться педагогическими принципами, сохраняющими интерпретативное чтение и критическое письмо в качестве центральных элементов высшего образования (с. 7).

Раздел о переопределении обучения и оценивания затрагивает вопрос, который недостаточно разработан в текущей литературе и крайне релевантен для понимания того, как институты адаптируются к новым реалиям. Авторы отмечают, что необходимо сместить фокус в сторону "ИИ-устойчивых" заданий, которые стимулируют критическую оценку и конструирование на основе ИИ-сгенерированного контента, а не просто его создание (с. 7). Это соотносится с вашей гипотезой H3 о том, что курсы часто не учитывают использование ИИ студентами, что приводит к проблемам валидности и конфликтам. Однако обзор Baldrich и соавторов выявляет, что существует значительный разрыв между позитивными восприятиями студентов и преподавателей относительно потенциала ИИ в образовании и фактической готовностью к его интеграции (с. 6). Многие институты и преподаватели не подготовлены к быстрой интеграции генеративного ИИ, поскольку им не хватает четких руководств и возможностей профессионального развития.

Для моего исследования особенно важна методологическая часть статьи. Авторы подробно описывают инструменты и процессы валидации, которые были использованы в отобранных исследованиях. Корпус работ демонстрирует преобладание количественной методологии с инструментами, разработанными и подвергнутыми строгой статистической валидации, включая факторный анализ, моделирование структурных уравнений и корреляционные тесты. Это обеспечивает надежную основу для выбора методов в моем собственном четырехпоточном дизайне исследования. Авторы рассматривают различные теоретические модели, включая классические модели принятия технологии (TAM, TPB, UTAUT), а также более недавние адаптации, специфичные для контекста ИИ. 

Однако есть и ограничения, которые следует учитывать. Во-первых, обзор охватывает период только с января 2023 по апрель 2025 года, хотя и совпадает с ускорением внедрения генеративного ИИ. Это означает, что длительные эффекты использования ИИ на развитие компетенций остаются в значительной степени не исследованными. Авторы сами подчеркивают необходимость пролонгированных исследований, которые могли бы отследить влияние ИИ на развитие академических компетенций во времени (с. 10). Во-вторых, хотя обзор охватывает различные дисциплины, есть смещение в сторону дисциплин гуманитарного профиля, особенно педагогических. Это может ограничить применимость выводов к точным наукам. В-третьих, лингвистическое смещение в сторону англоязычных публикаций означает, что опыт и контекст, специфичные для других регионов, включая Россию, остаются недостаточно представленными в обзоре.

